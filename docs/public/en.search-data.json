{"/docs/":{"data":{"features#Features":"🧠 Natural language to commands - Just describe what you want ⚡ Lightning fast - Cached responses are 100-400x faster 🔌 Universal compatibility - Works with Ollama, OpenAI, Claude, and more 🛡️ Safe by default - Preview commands before execution 📚 Learn while you work - Inline explanations for every command 🎯 Zero dependencies - Single compiled binary","quick-links#Quick Links":"Installation - Get vibe installed on your system Configuration - Configure your LLM provider Usage - Learn how to use vibe with examples Troubleshooting - Common issues and solutions Configuration Reference - Complete environment variable reference API Reference - Developer documentation","vibe-documentation#vibe Documentation":"vibe DocumentationWelcome to the vibe documentation! This guide will help you get started with transforming natural language into shell commands using AI.","what-is-vibe#What is vibe?":"vibe is a zsh plugin that transforms natural language into shell commands using AI. Just type what you want to do in plain English, press Ctrl+G, and get the command with inline explanations.\n# Type your intent in natural language list all docker containers # Press Ctrl+G # Get the command with explanations docker ps -a # docker: Docker command-line tool # ps: List containers # -a: Show all containers (not just running)"},"title":"Documentation"},"/docs/api/":{"data":{"":"This document describes the internal API and architecture of vibe for developers who want to understand how it works or contribute to the project.","1-zsh-plugin-vibepluginzsh#1. Zsh Plugin (\u003ccode\u003evibe.plugin.zsh\u003c/code\u003e)":"The entry point for user interaction.\nFunctions:\nvibe() Captures the current command buffer, sends it to the Go binary, and replaces the buffer with the generated command.\nKey Variables:\nVIBE_PLUGIN_DIR: Plugin installation directory VIBE_BINARY: Path to the Go binary BUFFER: Zsh variable containing current command line Keybinding:\nbindkey '^G' vibe","2-go-binary-cmdvibego#2. Go Binary (\u003ccode\u003ecmd/vibe.go\u003c/code\u003e)":"Main command-line interface.\nCommand Structure:\nvibe [flags] Flags:\nNone currently. Configuration is done via environment variables.\nExit Codes:\n0: Success 1: Error (details on stderr)","3-configuration-internalconfigconfiggo#3. Configuration (\u003ccode\u003einternal/config/config.go\u003c/code\u003e)":"Manages all configuration from environment variables.\nType:\ntype Config struct { APIURL string APIKey string Model string Temperature float64 MaxTokens int Timeout time.Duration ShowExplanation bool ShowWarnings bool EnableCache bool CacheTTL time.Duration Interactive bool } Loading:\ncfg := config.Load()","4-client-internalclientclientgo#4. Client (\u003ccode\u003einternal/client/client.go\u003c/code\u003e)":"Handles communication with OpenAI-compatible APIs.\nInterface:\ntype Client interface { Complete(ctx context.Context, prompt string) (*Response, error) } Request Structure:\ntype CompletionRequest struct { Model string `json:\"model\"` Messages []Message `json:\"messages\"` Temperature float64 `json:\"temperature\"` MaxTokens int `json:\"max_tokens\"` } Response Structure:\ntype Response struct { Command string Explanation []string Warning string }","5-parser-internalparsertext_parsergo#5. Parser (\u003ccode\u003einternal/parser/text_parser.go\u003c/code\u003e)":"Parses LLM responses into structured command + explanations.\nInterface:\ntype Parser interface { Parse(response string) (*ParsedCommand, error) } Output:\ntype ParsedCommand struct { Command string Explanation []string IsValid bool } Format:\nThe parser expects responses in this format:\ncommand # explanation line 1 # explanation line 2","6-cache-internalcachecachego#6. Cache (\u003ccode\u003einternal/cache/cache.go\u003c/code\u003e)":"File-based caching system for responses.\nInterface:\ntype Cache interface { Get(key string) (string, bool) Set(key string, value string, ttl time.Duration) error Clear() error } Cache Location:\n~/.cache/vibe/ Key Generation:\nkey := sha256(query + model + temperature)","7-schema-internalschemaschemago#7. Schema (\u003ccode\u003einternal/schema/schema.go\u003c/code\u003e)":"Defines the system prompt sent to the LLM.\nSystem Prompt:\nconst SystemPrompt = `You are a shell command generator...` This prompt instructs the LLM to:\nGenerate only valid shell commands Provide explanations as comments Warn about dangerous operations Be concise and accurate","adding-a-new-provider#Adding a New Provider":"Implement the Client interface Add provider-specific authentication Map provider response format to Response struct Add configuration options Update documentation","architecture-overview#Architecture Overview":"┌─────────────────┐ │ Zsh Plugin │ │ (vibe.plugin) │ └────────┬────────┘ │ │ Captures buffer │ on Ctrl+G ▼ ┌─────────────────┐ │ Go Binary │ │ (cmd/vibe.go) │ └────────┬────────┘ │ ├─────────────────┐ │ │ ▼ ▼ ┌─────────────────┐ ┌──────────────┐ │ Cache Layer │ │ LLM Client │ │ (internal/cache)│ │(internal/ │ │ │ │ client) │ └─────────────────┘ └──────┬───────┘ │ │ OpenAI API ▼ ┌──────────────┐ │ LLM Provider│ │ (Ollama/GPT) │ └──────────────┘","building#Building":"make build # Current platform make build-all # All platforms","code-style#Code Style":"Follow standard Go conventions Use gofmt for formatting Add tests for new functionality Update documentation","contributing#Contributing":"See the main README for contribution guidelines.","core-components#Core Components":"","dependencies#Dependencies":"vibe uses only the Go standard library:\nnet/http: HTTP client encoding/json: JSON parsing crypto/sha256: Cache key generation os, io, time, context: Standard utilities No external dependencies = simple, secure, maintainable code.","development#Development":"","error-handling#Error Handling":"All errors are returned on stderr with descriptive messages:\nif err != nil { fmt.Fprintf(os.Stderr, \"vibe: %v\\n\", err) os.Exit(1) }","extending-functionality#Extending Functionality":"Adding a new configuration option:\nAdd to Config struct in internal/config/config.go Add environment variable parsing Update documentation Add tests Modifying the system prompt:\nEdit internal/schema/schema.go Test with multiple LLM providers Ensure backward compatibility","integration-tests#Integration Tests":"Test with live API:\nexport VIBE_API_URL=\"http://localhost:11434/v1\" export VIBE_MODEL=\"llama3:8b\" ./vibe \"list all files\"","pull-request-process#Pull Request Process":"Fork the repository Create a feature branch Make your changes Add tests Update documentation Submit PR","request-flow#Request Flow":"User Input\nUser types natural language Presses Ctrl+G Zsh Plugin\nCaptures $BUFFER Calls Go binary: vibe \"$BUFFER\" Configuration\nLoads environment variables Validates settings Cache Check\nGenerates cache key from query + config Returns cached response if available LLM Request\nConstructs completion request Sends to configured API Applies retry logic with backoff Response Parsing\nExtracts command and explanations Validates format Output\nWrites to stdout Go binary exits Zsh Plugin\nReads stdout Replaces $BUFFER with command Shows explanations as comments","testing#Testing":"","unit-tests#Unit Tests":"Run all tests:\nmake test Test specific package:\ngo test ./internal/parser"},"title":"API Reference"},"/docs/configuration/":{"data":{"":"All configuration is done through environment variables in your ~/.zshrc. All settings are optional and have sensible defaults.","anthropic-via-openrouter#Anthropic (via OpenRouter)":"export VIBE_API_URL=\"https://openrouter.ai/api/v1\" export VIBE_API_KEY=\"sk-or-...\" export VIBE_MODEL=\"anthropic/claude-3.5-sonnet\"","api-settings#API Settings":"Set request timeout (default: 30s):\nexport VIBE_TIMEOUT=60s Set generation temperature (default: 0.7):\nexport VIBE_TEMPERATURE=0.3 Lower temperature = more deterministic, higher = more creative.\nSet maximum response tokens (default: 500):\nexport VIBE_MAX_TOKENS=1000","behavior-configuration#Behavior Configuration":"","cache-settings#Cache Settings":"Enable/disable response caching (default: true):\nexport VIBE_ENABLE_CACHE=false Set cache lifetime (default: 24h):\nexport VIBE_CACHE_TTL=12h Caching dramatically improves performance for repeated queries. Cached responses are 100-400x faster.","configuration-reference#Configuration Reference":"Variable Default Description VIBE_API_URL http://localhost:11434/v1 API endpoint URL VIBE_API_KEY \"\" API key (if required) VIBE_MODEL llama3:8b Model to use VIBE_TEMPERATURE 0.7 Generation temperature VIBE_MAX_TOKENS 500 Max response tokens VIBE_TIMEOUT 30s Request timeout VIBE_SHOW_EXPLANATION true Show command explanations VIBE_SHOW_WARNINGS true Show warnings for dangerous commands VIBE_ENABLE_CACHE true Enable response caching VIBE_CACHE_TTL 24h Cache lifetime VIBE_INTERACTIVE false Confirm before inserting","example-configuration#Example Configuration":"Here’s a complete example configuration in your ~/.zshrc:\n# vibe configuration export VIBE_API_URL=\"https://api.openai.com/v1\" export VIBE_API_KEY=\"sk-...\" export VIBE_MODEL=\"gpt-4\" export VIBE_TEMPERATURE=0.5 export VIBE_SHOW_EXPLANATION=true export VIBE_INTERACTIVE=false export VIBE_ENABLE_CACHE=true export VIBE_CACHE_TTL=24h","groq#Groq":"export VIBE_API_URL=\"https://api.groq.com/openai/v1\" export VIBE_API_KEY=\"gsk_...\" export VIBE_MODEL=\"llama-3.1-70b-versatile\"","interactive-mode#Interactive Mode":"Require confirmation before inserting commands (default: false):\nexport VIBE_INTERACTIVE=true When enabled, vibe will show the command and ask for confirmation before inserting it into your prompt.","lm-studio#LM Studio":"export VIBE_API_URL=\"http://localhost:1234/v1\" export VIBE_MODEL=\"local-model\"","local-llm-ollama---default#Local LLM (Ollama) - Default":"export VIBE_API_URL=\"http://localhost:11434/v1\" export VIBE_MODEL=\"llama3:8b\" This is the default configuration. If you have Ollama running locally, vibe will work out of the box.","openai#OpenAI":"export VIBE_API_URL=\"https://api.openai.com/v1\" export VIBE_API_KEY=\"sk-...\" export VIBE_MODEL=\"gpt-4\"","performance-configuration#Performance Configuration":"","provider-configuration#Provider Configuration":"","showhide-explanations#Show/Hide Explanations":"Control whether command explanations are displayed (default: true):\nexport VIBE_SHOW_EXPLANATION=false","showhide-warnings#Show/Hide Warnings":"Control whether warnings are shown for dangerous commands (default: true):\nexport VIBE_SHOW_WARNINGS=false"},"title":"Configuration"},"/docs/installation/":{"data":{"":"","1-clone-the-repository#1. Clone the repository":"git clone https://github.com/skymoore/vibe-zsh.git ~/.oh-my-zsh/custom/plugins/vibe","2-build-the-binary#2. Build the binary":"cd ~/.oh-my-zsh/custom/plugins/vibe make build","3-add-to-your-zshrc#3. Add to your \u003ccode\u003e.zshrc\u003c/code\u003e":"Edit your ~/.zshrc and add vibe to the plugins array:\nplugins=(... vibe)","4-reload-your-shell#4. Reload your shell":"source ~/.zshrc","building-from-source#Building from Source":"If you want to build from source:\ngit clone https://github.com/skymoore/vibe-zsh.git cd vibe-zsh make build # Build for current platform make build-all # Build for all platforms make test # Run tests make install # Install to oh-my-zsh","manual-install#Manual Install":"If you prefer to install manually:","next-steps#Next Steps":"After installation, you’ll want to configure your API settings.","one-line-install#One-Line Install":"The easiest way to install vibe is using our automated installation script:\ncurlwget curl -fsSL https://raw.githubusercontent.com/skymoore/vibe-zsh/main/install.sh | bash wget -qO- https://raw.githubusercontent.com/skymoore/vibe-zsh/main/install.sh | bash This script will:\nClone the repository to ~/.oh-my-zsh/custom/plugins/vibe Build the binary for your platform Add the plugin to your .zshrc Reload your shell","verification#Verification":"After installation, verify that vibe is working:\n# Check that the binary exists which vibe # Type something and press Ctrl+G echo \"test\" # Then press Ctrl+G"},"title":"Installation"},"/docs/reference/":{"data":{"":"Complete reference for all vibe configuration options.","anthropic-via-openrouter#Anthropic (via OpenRouter)":"export VIBE_API_URL=\"https://openrouter.ai/api/v1\" export VIBE_API_KEY=\"sk-or-...\" export VIBE_MODEL=\"anthropic/claude-3.5-sonnet\" export VIBE_TEMPERATURE=0.7 export VIBE_MAX_TOKENS=500","api-configuration#API Configuration":"","applying-configuration-changes#Applying Configuration Changes":"After modifying environment variables in ~/.zshrc:\nsource ~/.zshrc Or restart your terminal.","behavior-configuration#Behavior Configuration":"","cache-configuration#Cache Configuration":"","common-issues#Common Issues":"“Connection refused”\nCheck VIBE_API_URL is correct Verify service is running (e.g., ollama serve) “Unauthorized” or “Invalid API key”\nVerify VIBE_API_KEY is set and correct Check for extra quotes or spaces “Model not found”\nVerify VIBE_MODEL exists for your provider For Ollama: ollama list Slow responses\nEnable cache: VIBE_ENABLE_CACHE=true Reduce VIBE_MAX_TOKENS Use faster model or local LLM","complete-configuration-example#Complete Configuration Example":"# API Configuration export VIBE_API_URL=\"https://api.openai.com/v1\" export VIBE_API_KEY=\"sk-...\" export VIBE_MODEL=\"gpt-4\" export VIBE_TEMPERATURE=0.5 export VIBE_MAX_TOKENS=500 export VIBE_TIMEOUT=30s # Display Configuration export VIBE_SHOW_EXPLANATION=true export VIBE_SHOW_WARNINGS=true # Behavior Configuration export VIBE_INTERACTIVE=false # Cache Configuration export VIBE_ENABLE_CACHE=true export VIBE_CACHE_TTL=24h","configuration-files#Configuration Files":"vibe uses environment variables only - no configuration files are required or used.\nCache location:\n~/.cache/vibe/ Plugin location:\n~/.oh-my-zsh/custom/plugins/vibe/ To reset cache:\nrm -rf ~/.cache/vibe/*","configuration-templates#Configuration Templates":"","display-configuration#Display Configuration":"","environment-variables#Environment Variables":"All configuration is done through environment variables in your ~/.zshrc.","groq#Groq":"export VIBE_API_URL=\"https://api.groq.com/openai/v1\" export VIBE_API_KEY=\"gsk_...\" export VIBE_MODEL=\"llama-3.1-70b-versatile\" export VIBE_TEMPERATURE=0.4","local-llm-ollama#Local LLM (Ollama)":"# Minimal configuration (uses defaults) export VIBE_API_URL=\"http://localhost:11434/v1\" export VIBE_MODEL=\"llama3:8b\"","openai#OpenAI":"export VIBE_API_URL=\"https://api.openai.com/v1\" export VIBE_API_KEY=\"sk-...\" export VIBE_MODEL=\"gpt-4\" export VIBE_TEMPERATURE=0.5 export VIBE_TIMEOUT=30s","plugin-configuration#Plugin Configuration":"","quick-reference-table#Quick Reference Table":"Variable Type Default Description VIBE_API_URL String http://localhost:11434/v1 API endpoint URL VIBE_API_KEY String \"\" API authentication key VIBE_MODEL String llama3:8b Model identifier VIBE_TEMPERATURE Float 0.7 Randomness (0.0-2.0) VIBE_MAX_TOKENS Integer 500 Max response tokens VIBE_TIMEOUT Duration 30s Request timeout VIBE_SHOW_EXPLANATION Boolean true Show explanations VIBE_SHOW_WARNINGS Boolean true Show warnings VIBE_INTERACTIVE Boolean false Confirm before insert VIBE_ENABLE_CACHE Boolean true Enable caching VIBE_CACHE_TTL Duration 24h Cache lifetime VIBE_BINARY String Auto Binary path","test-configuration#Test Configuration":"Test with a simple query:\n~/.oh-my-zsh/custom/plugins/vibe/vibe \"list files\"","troubleshooting-configuration#Troubleshooting Configuration":"","vibe_api_key#VIBE_API_KEY":"Type: String\nDefault: \"\" (empty, not required for Ollama)\nDescription: API key for authentication. Required for most cloud providers.\nExamples:\n# OpenAI export VIBE_API_KEY=\"sk-...\" # OpenRouter export VIBE_API_KEY=\"sk-or-...\" # Groq export VIBE_API_KEY=\"gsk_...\" Security Note: Never commit API keys to version control.","vibe_api_url#VIBE_API_URL":"Type: String\nDefault: http://localhost:11434/v1\nDescription: The base URL for the OpenAI-compatible API endpoint.\nExamples:\n# Ollama (local) export VIBE_API_URL=\"http://localhost:11434/v1\" # OpenAI export VIBE_API_URL=\"https://api.openai.com/v1\" # Anthropic via OpenRouter export VIBE_API_URL=\"https://openrouter.ai/api/v1\" # LM Studio export VIBE_API_URL=\"http://localhost:1234/v1\" # Groq export VIBE_API_URL=\"https://api.groq.com/openai/v1\"","vibe_binary#VIBE_BINARY":"Type: String\nDefault: ${VIBE_PLUGIN_DIR}/vibe\nDescription: Path to the vibe binary. Override if you want to use a custom binary location.\nExample:\nexport VIBE_BINARY=\"/usr/local/bin/vibe\"","vibe_cache_ttl#VIBE_CACHE_TTL":"Type: Duration\nDefault: 24h\nDescription: How long cached responses remain valid.\nExamples:\n# 1 hour export VIBE_CACHE_TTL=1h # 12 hours export VIBE_CACHE_TTL=12h # 24 hours (default) export VIBE_CACHE_TTL=24h # 7 days export VIBE_CACHE_TTL=168h Format: Number + unit (h for hours, m for minutes)\nCache location: ~/.cache/vibe/","vibe_enable_cache#VIBE_ENABLE_CACHE":"Type: Boolean\nDefault: true\nDescription: Enable response caching for faster repeated queries.\nExamples:\n# Enable cache (default) export VIBE_ENABLE_CACHE=true # Disable cache export VIBE_ENABLE_CACHE=false Impact:\nEnabled: Cached queries return in ~5-10ms (100-400x faster) Disabled: Every query hits the API","vibe_interactive#VIBE_INTERACTIVE":"Type: Boolean\nDefault: false\nDescription: Require confirmation before inserting commands into the prompt.\nExamples:\n# Auto-insert (default) export VIBE_INTERACTIVE=false # Require confirmation export VIBE_INTERACTIVE=true When enabled:\n--- docker ps -a --- Execute this command? [Y/n]","vibe_max_tokens#VIBE_MAX_TOKENS":"Type: Integer\nDefault: 500\nDescription: Maximum number of tokens in the API response.\nExamples:\n# Shorter responses (faster) export VIBE_MAX_TOKENS=300 # Default export VIBE_MAX_TOKENS=500 # Longer responses (for complex commands) export VIBE_MAX_TOKENS=1000 Note: Higher values increase API costs and response time.","vibe_model#VIBE_MODEL":"Type: String\nDefault: llama3:8b\nDescription: The model identifier to use for command generation.\nExamples:\n# Ollama export VIBE_MODEL=\"llama3:8b\" export VIBE_MODEL=\"llama3.1:70b\" export VIBE_MODEL=\"codellama:13b\" # OpenAI export VIBE_MODEL=\"gpt-4\" export VIBE_MODEL=\"gpt-4-turbo\" export VIBE_MODEL=\"gpt-3.5-turbo\" # Anthropic (via OpenRouter) export VIBE_MODEL=\"anthropic/claude-3.5-sonnet\" export VIBE_MODEL=\"anthropic/claude-3-opus\" # Groq export VIBE_MODEL=\"llama-3.1-70b-versatile\" export VIBE_MODEL=\"mixtral-8x7b-32768\"","vibe_plugin_dir#VIBE_PLUGIN_DIR":"Type: String (read-only)\nDefault: Auto-detected\nDescription: Directory where the vibe plugin is installed. Automatically set by the plugin.\n# Typically: ~/.oh-my-zsh/custom/plugins/vibe","vibe_show_explanation#VIBE_SHOW_EXPLANATION":"Type: Boolean\nDefault: true\nDescription: Show inline explanations for generated commands.\nExamples:\n# Show explanations (default) export VIBE_SHOW_EXPLANATION=true # Hide explanations export VIBE_SHOW_EXPLANATION=false When enabled:\ndocker ps -a # docker: Docker command-line tool # ps: List containers # -a: Show all containers (not just running) When disabled:\ndocker ps -a","vibe_show_warnings#VIBE_SHOW_WARNINGS":"Type: Boolean\nDefault: true\nDescription: Display warnings for potentially dangerous commands.\nExamples:\n# Show warnings (default) export VIBE_SHOW_WARNINGS=true # Hide warnings export VIBE_SHOW_WARNINGS=false When enabled:\n⚠️ WARNING: This command may delete files rm -rf *","vibe_temperature#VIBE_TEMPERATURE":"Type: Float\nDefault: 0.7\nRange: 0.0 to 2.0\nDescription: Controls randomness in the model’s output. Lower values make output more deterministic, higher values more creative.\nExamples:\n# More deterministic (recommended for commands) export VIBE_TEMPERATURE=0.3 # Balanced (default) export VIBE_TEMPERATURE=0.7 # More creative export VIBE_TEMPERATURE=1.0 Recommendations:\n0.0-0.3: Most consistent, predictable commands 0.4-0.7: Balanced creativity and consistency 0.8-2.0: More variation (may produce unexpected results)","vibe_timeout#VIBE_TIMEOUT":"Type: Duration\nDefault: 30s\nDescription: Maximum time to wait for API response.\nExamples:\n# Shorter timeout export VIBE_TIMEOUT=15s # Default export VIBE_TIMEOUT=30s # Longer timeout (slow connections) export VIBE_TIMEOUT=60s Format: Number + unit (s for seconds, m for minutes)","view-current-configuration#View Current Configuration":"Check what vibe sees:\nenv | grep VIBE_"},"title":"Configuration Reference"},"/docs/troubleshooting/":{"data":{"":"","api-connection-errors#API Connection Errors":"Symptoms: Errors like “connection refused” or “timeout.”\nSolutions:\nFor Ollama - check if it’s running:\ncurl http://localhost:11434/v1/models Start Ollama if needed:\nollama serve Verify API URL is correct:\necho $VIBE_API_URL Check API key is set (if using OpenAI/Claude):\necho $VIBE_API_KEY # Should not be empty Test API directly:\ncurl -H \"Authorization: Bearer $VIBE_API_KEY\" $VIBE_API_URL/models","bad-command-suggestions#Bad Command Suggestions":"Symptoms: Generated commands don’t match your intent or are incorrect.\nSolutions:\nTry a different/better model:\nexport VIBE_MODEL=\"gpt-4\" # Or other capable models Make your query more specific:\n❌ “list files” ✅ “list all files in current directory including hidden ones with sizes” Check model supports structured output: Some models may not follow the expected output format.\nLower temperature for more deterministic results:\nexport VIBE_TEMPERATURE=0.3 Clear cache if getting stale results:\nrm -rf ~/.cache/vibe/*","cache-issues#Cache Issues":"Symptoms: Getting outdated commands or cache-related errors.\nSolutions:\nClear the cache:\nrm -rf ~/.cache/vibe/* Disable cache temporarily:\nexport VIBE_ENABLE_CACHE=false Reduce cache TTL:\nexport VIBE_CACHE_TTL=1h","command-not-working-after-install#Command Not Working After Install":"Symptoms: Pressing Ctrl+G does nothing, or you get “command not found” errors.\nSolutions:\nReload your shell:\nsource ~/.zshrc Verify plugin is loaded:\necho $plugins # Should include \"vibe\" Check binary exists:\nls ~/.oh-my-zsh/custom/plugins/vibe/vibe # Should show the binary Verify function is loaded:\nwhich vibe # Should show \"vibe\" as a shell function Rebuild the binary:\ncd ~/.oh-my-zsh/custom/plugins/vibe make clean build","ctrlg-does-nothing#Ctrl+G Does Nothing":"Symptoms: Pressing Ctrl+G has no effect.\nSolutions:\nCheck if another plugin uses Ctrl+G:\nbindkey | grep '\"\\^G\"' Rebind to different key:\nbindkey '^X' vibe # Use Ctrl+X instead Ensure plugin is loaded:\necho $plugins | grep vibe Reload shell:\nsource ~/.zshrc","model-not-found#Model Not Found":"Symptoms: Error messages about model not being available.\nSolutions:\nFor Ollama - pull the model:\nollama pull llama3:8b List available models:\n# Ollama ollama list # OpenAI curl https://api.openai.com/v1/models \\ -H \"Authorization: Bearer $VIBE_API_KEY\" Use a different model:\nexport VIBE_MODEL=\"llama3:8b\"","permission-denied#Permission Denied":"Symptoms: “Permission denied” when trying to execute vibe binary.\nSolutions:\nMake binary executable:\nchmod +x ~/.oh-my-zsh/custom/plugins/vibe/vibe Rebuild binary:\ncd ~/.oh-my-zsh/custom/plugins/vibe make clean build","slow-responses#Slow Responses":"Symptoms: vibe takes several seconds to respond.\nSolutions:\nEnable caching:\nexport VIBE_ENABLE_CACHE=true Cached responses are 100-400x faster!\nUse a faster model:\nexport VIBE_MODEL=\"llama3:8b\" # Instead of larger models Use a local LLM:\nexport VIBE_API_URL=\"http://localhost:11434/v1\" export VIBE_MODEL=\"llama3:8b\" Check network connection:\ncurl -I $VIBE_API_URL Increase timeout if needed:\nexport VIBE_TIMEOUT=60s","still-having-issues#Still Having Issues?":"If you’re still experiencing problems:\nCheck the logs:\n# vibe logs errors to stderr vibe \"test query\" 2\u003e\u00261 Enable debug mode (if available):\nexport VIBE_DEBUG=true Report the issue:\nVisit: https://github.com/skymoore/vibe-zsh/issues Include: Your OS and version Zsh version: zsh --version Oh-My-Zsh version vibe configuration (environment variables) Error messages or unexpected behavior Join the community:\nCheck existing issues for solutions Ask questions in discussions Contribute fixes if you find them!"},"title":"Troubleshooting"},"/docs/usage/":{"data":{"":"","advanced-features#Advanced Features":"","basic-usage#Basic Usage":"Using vibe is simple:\nType a natural language description in your terminal Press Ctrl+G Review the generated command (with explanations) Press Enter to execute, or edit first","be-specific#Be Specific":"More specific queries generate better commands:\n❌ Vague: “list files” ✅ Specific: “list all files including hidden ones with human-readable sizes”","combine-with-other-tools#Combine with Other Tools":"Vibe-generated commands work with pipes and other shell features:\n# Generate: docker ps # Edit to: docker ps | grep nginx","command-explanations#Command Explanations":"By default, vibe shows explanations for each part of the command:\ndocker ps -a # docker: Docker command-line tool # ps: List containers # -a: Show all containers (not just running) To hide explanations:\nexport VIBE_SHOW_EXPLANATION=false","docker#Docker":"show logs of nginx container and follow them # Press Ctrl+G # → docker logs -f nginx list all docker containers including stopped ones # Press Ctrl+G # → docker ps -a remove all stopped containers # Press Ctrl+G # → docker container prune","edit-generated-commands#Edit Generated Commands":"The generated command is editable. Use arrow keys to modify it before executing:\n# Generated: git log --since=\"1 week ago\" # Edit to: git log --since=\"2 weeks ago\" --author=\"yourname\"","examples#Examples":"","file-operations#File Operations":"show me all hidden files including their sizes # Press Ctrl+G # → ls -lah find all python files modified today # Press Ctrl+G # → find . -name \"*.py\" -mtime 0 compress all log files into an archive # Press Ctrl+G # → tar -czf logs.tar.gz *.log","git#Git":"show me commits from last week # Press Ctrl+G # → git log --since=\"1 week ago\" undo the last commit but keep the changes # Press Ctrl+G # → git reset --soft HEAD~1 show me what changed in the last commit # Press Ctrl+G # → git show HEAD","interactive-mode#Interactive Mode":"When VIBE_INTERACTIVE=true, vibe will ask for confirmation before inserting commands:\nexport VIBE_INTERACTIVE=true # Type: delete all log files # Press Ctrl+G --- rm *.log --- Execute this command? [Y/n]","keybindings#Keybindings":"Key Action Ctrl+G Generate command from natural language To change the keybinding, add this to your .zshrc:\nbindkey '^X' vibe # Use Ctrl+X instead","network#Network":"test if port 443 is open on example.com # Press Ctrl+G # → nc -zv example.com 443 show my public ip address # Press Ctrl+G # → curl ifconfig.me download a file and show progress # Press Ctrl+G # → curl -# -O","review-before-executing#Review Before Executing":"Always review the generated command before pressing Enter. Vibe is a tool to help you, not to blindly execute commands.","safety-warnings#Safety Warnings":"Vibe will warn you about potentially dangerous commands:\n# Type: delete everything in current directory # Press Ctrl+G ⚠️ WARNING: This command may delete files rm -rf * To disable warnings:\nexport VIBE_SHOW_WARNINGS=false","system-administration#System Administration":"show disk usage of all mounted filesystems # Press Ctrl+G # → df -h find processes listening on port 8080 # Press Ctrl+G # → lsof -i :8080 show memory usage sorted by process # Press Ctrl+G # → ps aux --sort=-%mem | head","tab-completion#Tab Completion":"Vibe provides tab completion for common queries:\nvibe # Shows common query suggestions","tips-and-best-practices#Tips and Best Practices":"","use-natural-language#Use Natural Language":"Write how you would explain the task to someone:\n✅ “show me all processes using more than 100MB of memory” ✅ “find all files larger than 1GB modified in the last hour”"},"title":"Usage"}}